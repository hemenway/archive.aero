# File Specification Document (FSD)
## Archive.aero - Historical Aeronautical Chart Viewer System

**Version:** 2.5
**Last Updated:** 2026-01-15
**Maintainer:** Ryan Hemenway

---

## Table of Contents

1. [System Overview](#system-overview)
2. [Architecture](#architecture)
3. [Frontend Specification (index.html)](#frontend-specification-indexhtml)
4. [Backend Specification (newslicer.py)](#backend-specification-newslicerpy)
5. [PMTiles Conversion](#pmtiles-conversion)
6. [Data Specifications](#data-specifications)
7. [Tile System Specification](#tile-system-specification)
8. [Deployment](#deployment)
9. [Performance Considerations](#performance-considerations)
10. [Security Considerations](#security-considerations)
11. [Testing & Quality Assurance](#testing--quality-assurance)
12. [Maintenance & Operations](#maintenance--operations)
13. [Future Enhancements](#future-enhancements)
14. [Glossary](#glossary)
15. [References](#references)
16. [Changelog](#changelog)
17. [License & Attribution](#license--attribution)

---

## 1. System Overview

### 1.1 Purpose
The Archive.aero system provides interactive visualization of historical FAA aeronautical sectional charts spanning from 2011 to present. The system consists of two main components:

1. **Frontend Viewer** (`index.html`) - Web-based interactive map interface
2. **Backend Processor** (`newslicer.py`) - Python CLI tool for chart processing, COG/tile generation, and PMTiles conversion

### 1.2 Technology Stack

**Frontend:**
- HTML5/CSS3/JavaScript (ES6+)
- Leaflet.js 1.9.4 (mapping library)
- PapaParse 5.4.1 (CSV parsing)
- Plausible Analytics (privacy-friendly analytics)

**Backend:**
- Python 3.7+
- GDAL/OGR (geospatial processing)
- gdal2tiles.py (tile generation)
- PMTiles (vector tile format conversion)

### 1.3 Data Flow

```
Raw Chart TIFFs → newslicer.py → COG/GeoTIFF/Web Tiles → PMTiles (optional)
                        ↓                                      ↓
                dates.csv metadata                             ↓
                        ↓                                      ↓
                    index.html viewer ←───────────────────────┘

PMTiles Conversion Pipeline (optional):
  input_cog.tif → gdal_translate -of MBTILES → out.mbtiles
  out.mbtiles → gdaladdo -r bilinear → out.mbtiles (with overviews)
  out.mbtiles → pmtiles convert → out.pmtiles
```

---

## 2. Architecture

### 2.1 System Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                     User's Web Browser                       │
│  ┌──────────────────────────────────────────────────────┐   │
│  │              index.html (Frontend)                    │   │
│  │  - Leaflet Map Engine                                 │   │
│  │  - Timeline Controller                                │   │
│  │  - UI Components                                      │   │
│  └──────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────┘
                           ↓ HTTPS
┌─────────────────────────────────────────────────────────────┐
│              CDN / Static File Server                        │
│                                                              │
│  /dates.csv          - Timeline metadata                    │
│  /2011-10-15/        - Tile directory for date              │
│    ├── 0/0/0.webp    - Zoom 0 tiles                        │
│    ├── 1/0/0.webp    - Zoom 1 tiles                        │
│    └── ...                                                  │
│                                                              │
│  Origin: https://data.archive.aero/sectionals/              │
└─────────────────────────────────────────────────────────────┘
                           ↑
                    Generated by
                           ↓
┌─────────────────────────────────────────────────────────────┐
│              newslicer.py (Backend Processor)                │
│                                                              │
│  ┌──────────────┐   ┌──────────────┐   ┌──────────────┐   │
│  │   Chart      │   │     GDAL     │   │    Output    │   │
│  │  Processor   │→→→│   Warping    │→→→│  Generator   │   │
│  │              │   │  & Mosaicking │   │ (COG/Tiles)  │   │
│  └──────────────┘   └──────────────┘   └──────────────┘   │
│                                                              │
│  Input: Raw TIFFs + Shapefiles + CSV                        │
│  Output: COG/GeoTIFF/WebP Tiles                             │
└─────────────────────────────────────────────────────────────┘
                           ↓ (optional)
┌─────────────────────────────────────────────────────────────┐
│              PMTiles Conversion Pipeline                     │
│                                                              │
│  gdal_translate -of MBTILES → gdaladdo → pmtiles convert    │
│  Input: COG/GeoTIFF                                          │
│  Output: PMTiles                                             │
└─────────────────────────────────────────────────────────────┘
```

### 2.2 Directory Structure

```
archive.aero/
├── index.html                    # Frontend viewer
├── dates.csv                     # Timeline metadata
├── master_dole.csv              # Backend metadata (chart locations/editions)
├── FSD.md                        # This document
├── newslicer.py                 # Backend processor (CLI)
├── shapefiles/                   # Chart boundary definitions (56 locations)
│   ├── seattle.shp
│   ├── dallas_ft_worth.shp
│   └── ...
└── output/                       # Generated output
    ├── 2011-10-15/
    │   ├── .temp/                # Temporary warped files
    │   ├── mosaic_2011-10-15.vrt
    │   ├── mosaic_2011-10-15.tif # GeoTIFF output (if selected)
    │   └── tiles/                # Tile output (if selected)
    │       ├── 0/0/0.webp
    │       └── ...
    └── 2025-08-07/
        └── ...
```

---

## 3. Frontend Specification (index.html)

### 3.1 Overview

Single-page application (SPA) that provides an interactive timeline-based map viewer for historical aeronautical charts.

### 3.2 Global Configuration

```javascript
const CONFIG = {
  baseUrl: 'https://data.archive.aero/sectionals/',
  csvUrl: 'dates.csv',
  initialView: { center: [32.7767, -96.7970], zoom: 10 },
  frames: []  // Populated from CSV
};
```

**Configuration Parameters:**

| Parameter | Type | Description |
|-----------|------|-------------|
| `baseUrl` | String | Base URL for tile data |
| `csvUrl` | String | Path to timeline metadata CSV |
| `initialView.center` | Array[2] | Initial map center [lat, lng] |
| `initialView.zoom` | Number | Initial zoom level (0-22) |
| `frames` | Array | Timeline frames (populated dynamically) |

### 3.3 Core Classes

#### 3.3.1 MapController

**Purpose:** Manages Leaflet map instance and chart layer rendering.

**Constructor:**
```javascript
constructor(mapId: String)
```

**Properties:**
- `map` - Leaflet map instance
- `cache` - Object storing layer data by date
- `activeLayers` - Array of currently displayed layers

**Methods:**

**`getLayerData(date: String): Object`**
- Returns cached layer data or creates new tile layer
- Returns: `{ layer: L.TileLayer }`

**`async showFrame(index: Number): void`**
- Displays charts for the specified frame index
- Implements 167-day rolling window
- Manages layer z-index for proper stacking
- Updates opacity based on UI settings

**Layer Management Logic:**
```javascript

// Filter frames within window
const activeFrames = CONFIG.frames.filter(f => {
  const d = new Date(f.date);
  return d >= cutoffDate && d <= currentDate;
});


**Tile URL Template:**
```
https://data.archive.aero/sectionals/{date}/{z}/{x}/{y}.webp
```

**Coordinate System:**
- Projection: Web Mercator (EPSG:3857)
- Tile Scheme: XYZ (standard web tiles)
- Tile Size: 256x256 pixels
- Format: WebP

#### 3.3.2 TimelineApp

**Purpose:** Controls timeline UI and user interactions.

**Constructor:**
```javascript
constructor(mapController: MapController)
```

**Properties:**
- `mapCtrl` - Reference to MapController
- `frames` - Array of timeline frames
- `currentIndex` - Current frame index
- `isPlaying` - Boolean playback state
- `playInterval` - Interval timer for playback
- `ui` - Object containing DOM element references

**Methods:**

**`update(index: Number, lazy: Boolean = false): void`**
- Updates timeline to specified index
- If `lazy=true`, uses debounced version for scrubbing
- Updates handle position, progress bar, active tick

**`step(direction: Number): void`**
- Steps timeline forward (+1) or backward (-1)
- Wraps around at boundaries

**`togglePlay(): void`**
- Toggles playback mode
- Playback interval: 2000ms per frame

**`updateShareUrl(): void`**
- Generates shareable URL with current state
- Format: `?date={date}&lat={lat}&lng={lng}&zoom={zoom}`

**`hideAllPanels(except: Array = []): void`**
- Closes all overlay panels except specified IDs

### 3.4 Data Loading

**CSV Format (dates.csv):**
```csv
date_iso
2011-10-15
2012-09-08
2013-02-15
...
```

**Loading Process:**
```javascript
async function loadData() {
  // Parse CSV using PapaParse
  Papa.parse(CONFIG.csvUrl, {
    download: true,
    header: true,
    skipEmptyLines: true,
    complete: (results) => {
      // Build frames array
      CONFIG.frames = results.data
        .filter(row => row.date_iso && row.date_iso !== '?')
        .map(row => ({
          id: Utils.formatDateId(row.date_iso),  // "Jan 2011"
          date: row.date_iso                      // "2011-01-15"
        }))
        .sort((a, b) => new Date(a.date) - new Date(b.date));
    }
  });
}
```

### 3.5 UI Components

#### 3.5.1 Timeline Track

**DOM Structure:**
```html
<div class="timeline-track-wrapper">
  <div class="timeline-track">
    <div class="timeline-progress"></div>
    <div id="ticksContainer"></div>
    <div class="handle"></div>
  </div>
</div>
```

**Interaction:**
- Click/Touch: Jump to frame
- Drag handle: Scrub through timeline
- Debounced: 250ms for smooth scrubbing

**Tick Generation:**
```javascript
frames.forEach((f, i) => {
  const tick = document.createElement('div');
  tick.className = 'tick';
  tick.style.left = `${f.pct}%`;  // Percentage position

  // Major ticks for years divisible by 5
  const year = parseInt(f.date.split('-')[0]);
  if (year % 5 === 0 || i === 0 || i === frames.length - 1) {
    tick.classList.add('major');
    // Add year label
  }
});
```

#### 3.5.2 Navigation Controls

**Jog Controls:**
- Previous (←): `step(-1)`
- Play/Pause (Space): `togglePlay()`
- Next (→): `step(+1)`

**Time Select Dropdown:**
- Populated from frames array
- Change event: `update(index)`

#### 3.5.3 Map Tools Panel

**Opacity Control:**
- Range slider: 0-100
- Updates all active layers in real-time

**Split View (Side-by-Side Comparison):**
- Creates second map instance
- Synchronized pan/zoom
- Independent timeline selection

#### 3.5.4 Location Search

**Geocoding Service:**
- Provider: OpenStreetMap Nominatim
- Endpoint: `https://nominatim.openstreetmap.org/search`
- Rate Limit: 1 request per second
- User-Agent: `AeroMap Historical Chart Viewer (https://archive.aero)`

**Auto-Location:**
- IP-based geolocation via `ipapi.co/json/`
- Silent fallback on failure
- Only runs if no URL parameters present

### 3.6 Keyboard Shortcuts

| Key | Action |
|-----|--------|
| `→` | Next frame |
| `←` | Previous frame |
| `Space` | Play/Pause |
| `F` | Toggle fullscreen |
| `S` | Open share panel |
| `?` | Show keyboard shortcuts |
| `Esc` | Close overlays |

### 3.7 URL Parameters

**Shareable Link Format:**
```
https://archive.aero/?date=2015-06-25&lat=32.7767&lng=-96.7970&zoom=10
```

**Parameters:**

| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `date` | String (ISO) | No | Initial date (YYYY-MM-DD) |
| `lat` | Float | No | Initial latitude |
| `lng` | Float | No | Initial longitude |
| `zoom` | Integer | No | Initial zoom level (0-22) |

### 3.8 Performance Optimizations

**Tile Layer Options:**
```javascript
L.tileLayer(tileUrl, {
  minZoom: 0,
  maxZoom: 22,
  tileSize: 256,
  opacity: 0,           // Fade in after load
  zIndex: 10 + frameIdx,
  keepBuffer: 2,        // Keep 2 tile rows around viewport
  updateWhenIdle: true, // Update only when map stops moving
  updateWhenZooming: false
});
```

**Debounced Timeline Scrubbing:**
- 250ms debounce prevents excessive rendering during drag
- Only final position triggers full layer update

**Layer Caching:**
- Tile layers cached by date in `MapController.cache`
- Prevents recreation of L.TileLayer instances
- Memory cleared automatically by Leaflet when layers removed

**Mobile Optimizations:**
- Skip `waitForLayer` on mobile (width < 640px)
- Instant layer swaps without waiting for tile loads
- Reduces perceived lag on slower devices

### 3.9 Browser Compatibility

**Minimum Requirements:**
- ES6 support (Arrow functions, template literals, async/await)
- CSS Grid and Flexbox
- Fetch API
- Clipboard API (for share functionality)

**Tested Browsers:**
- Chrome 90+
- Firefox 88+
- Safari 14+
- Edge 90+

**Fallbacks:**
- Clipboard API: Falls back to `document.execCommand('copy')`
- Backdrop filter: Degrades gracefully without blur effect

---

## 4. Backend Specification (newslicer.py)

### 4.1 Overview

Python CLI tool for processing FAA aeronautical charts into Cloud Optimized GeoTIFFs (COGs), standard GeoTIFFs, or WebP tile sets. The newslicer processes all dates in a master CSV file, applying a sophisticated fallback system to ensure all 56 chart locations are represented in each date's output using the most recent available data.

### 4.2 System Requirements

**Required:**
- Python 3.7+
- GDAL 3.0+ with Python bindings
- gdal2tiles.py (included with GDAL)
- zipfile (standard library)
- multiprocessing (standard library)

**Optional:**
- psutil (for dynamic RAM cache sizing)
- pmtiles CLI tool (for PMTiles conversion)
- Multi-core CPU (for parallel tile generation)

**Platform Support:**
- macOS 10.14+
- Linux (Ubuntu 20.04+, Debian 10+)
- Windows 10+ (with OSGeo4W GDAL)

### 4.3 Core Class: ChartSlicer

The `ChartSlicer` class is the primary processing engine that handles all chart operations.

**Constructor:**
```python
def __init__(self, source_dir: Path, output_dir: Path, csv_file: Path, shape_dir: Path)
```

**Properties:**
- `source_dir` - Directory containing raw chart TIFFs/ZIPs
- `output_dir` - Output directory for processed data
- `csv_file` - Path to master_dole.csv metadata file
- `shape_dir` - Directory containing shapefiles (56 locations)
- `file_index` - Dict mapping chart keys to file paths
- `dole_data` - Dict of chart metadata grouped by date
- `abbreviations` - Chart name normalization mappings
- `output_format` - Output format: 'geotiff', 'tiles', or 'both'
- `zoom_levels` - Zoom range string (e.g., '0-11')

#### 4.3.1 Key Methods

**`log(msg: str) -> None`**
- Logs messages with timestamp in format `[HH:MM:SS] message`

**`normalize_name(name: str) -> str`**
- Normalizes chart names for consistent matching
- Converts to lowercase, replaces spaces/dashes with underscores
- Applies abbreviation mappings

**`sanitize_filename(name: str) -> str`**
- Removes special characters from filenames for safe GDAL operations

**`scan_source_dir() -> None`**
- Recursively scans source directory for chart files
- Builds `file_index` with two key types:
  - `('EDITION', location, edition)` - Edition-based lookup
  - `('TS', timestamp)` - Timestamp-based lookup (from Wayback Machine)

**`load_dole_data() -> None`**
- Loads master_dole.csv metadata file
- Groups records by date
- Extracts Wayback Machine timestamps from download URLs

**`find_files(location: str, edition: str, timestamp: Optional[str]) -> List[Path]`**
- Finds matching chart files using fallback strategy:
  1. Timestamp match (Wayback Machine)
  2. Location + edition exact match
  3. Location + edition + suffix variations (sec, tac, sectional, terminal)
  4. Directional variants (north, south, east, west) with suffix variations

**`find_shapefile(location: str) -> Optional[Path]`**
- Matches chart location to shapefile using normalized names

**`unzip_file(zip_path: Path, output_dir: Path) -> List[Path]`**
- Extracts TIFFs and companion TFW files from ZIP archives
- Returns list of extracted TIFF paths

**`warp_and_cut(input_tiff: Path, shapefile: Path, output_tiff: Path) -> bool`**

Transforms and crops chart TIFF using shapefile boundary.

**Process:**
1. Expand to RGBA using VRT (in-memory: `/vsimem/`)
2. Warp to EPSG:3857 (Web Mercator)
3. Crop using shapefile cutline (EPSG:4326)
4. Output as tiled, LZW-compressed GeoTIFF with BIGTIFF support

**GDAL Options:**
```python
# Step 1: RGBA expansion
translate_options = gdal.TranslateOptions(format="VRT", rgbExpand="rgba")
ds_vrt = gdal.Translate("/vsimem/temp_rgba.vrt", str(input_tiff), options=translate_options)

# Step 2: Warp with cutline
warp_options = gdal.WarpOptions(
    format="GTiff",
    dstSRS='EPSG:3857',              # Web Mercator
    cutlineDSName=str(shapefile),
    cutlineSRS='EPSG:4326',          # Shapefile CRS
    cropToCutline=True,
    dstAlpha=True,
    resampleAlg=gdal.GRA_Bilinear,   # Bilinear resampling
    creationOptions=['TILED=YES', 'COMPRESS=LZW', 'BIGTIFF=YES'],
    multithread=True,
    warpOptions=['CUTLINE_ALL_TOUCHED=TRUE']
)
```

**Returns:** `True` on success, `False` on failure

---

**`build_vrt(input_files: List[Path], output_vrt: Path) -> bool`**

Combines multiple processed TIFFs/VRTs into virtual mosaic.

**Parameters:**
- `input_files` - List of warped GeoTIFF/VRT paths
- `output_vrt` - Output VRT file path

**GDAL Options:**
```python
vrt_options = gdal.BuildVRTOptions(
    resampleAlg=gdal.GRA_Bilinear
)
# Note: addAlpha not used - input files already have alpha from warp_and_cut
```

**Purpose:**
- Creates lightweight virtual dataset
- Mosaics multiple chart locations into single dataset
- No data duplication (references source files)

**Returns:** `True` on success, `False` on failure

---

**`create_geotiff(input_vrt: Path, output_tiff: Path, compress: str = 'LZW') -> bool`**

Converts VRT to optimized GeoTIFF.

**Parameters:**
- `input_vrt` - Source VRT file
- `output_tiff` - Output GeoTIFF path
- `compress` - Compression method (default: 'LZW')

**GDAL Options:**
```python
translate_options = gdal.TranslateOptions(
    format='GTiff',
    creationOptions=['TILED=YES', 'COMPRESS=LZW', 'BIGTIFF=YES', 'PREDICTOR=2']
)
```

**Returns:** `True` on success, `False` on failure

---

**`generate_tiles(input_vrt: Path, output_dir: Path, zoom_levels: str) -> bool`**

Generates XYZ web tiles using gdal2tiles.py.

**Parameters:**
- `input_vrt` - Source VRT file
- `output_dir` - Output directory for tiles
- `zoom_levels` - Zoom range (e.g., "0-11")

**Command:**
```bash
gdal2tiles.py \
  --zoom 0-11 \
  --processes 14 \              # CPU count - 2
  --webviewer=none \
  --exclude \                   # Exclude empty tiles
  --tiledriver=WEBP \
  --webp-quality=50 \           # Quality 50 (smaller files)
  input.vrt \
  output_dir/
```

**Note:** newslicer does NOT use the `--xyz` flag, which means it generates TMS tiles (Y-axis origin at bottom-left). For Leaflet compatibility, you may need to convert these tiles or adjust the frontend tile loading logic.

**Tile Structure:**
```
output_dir/
├── 0/
│   └── 0/
│       └── 0.webp        # World view
├── 1/
│   ├── 0/
│   │   ├── 0.webp
│   │   └── 1.webp
│   └── 1/
│       ├── 0.webp
│       └── 1.webp
└── ...
```

**Progress Monitoring:**
- Captures subprocess output with 2-hour timeout
- Logs stderr on failure

**Returns:** `True` on success, `False` on failure

---

**`process_all_dates() -> None`**

Main processing workflow that handles all dates in the master CSV with sophisticated fallback logic.

**Workflow:**

1. **Load all 56 shapefile locations**
   - Scans shape_dir for all .shp files
   - Normalizes location names

2. **For each date (latest to earliest):**
   - Load chart records from CSV
   - Create temporary directory (.temp/date/)

3. **Process each location for the date:**
   - Find shapefile for location
   - Find source files (TIFF/ZIP) using fallback logic
   - Extract ZIPs if needed
   - Warp and cut each TIFF with shapefile
   - Combine multiple warped files into location VRT
   - Store in `vrt_library[location][date]`

4. **Build date matrix with fallback:**
   - For each of the 56 locations:
     - Find most recent available date ≤ current date
     - Use that location's VRT (fallback logic)
   - This ensures every date has all 56 locations

5. **Create final mosaic:**
   - Build mosaic VRT from all 56 location VRTs
   - Generate output based on format:
     - `geotiff`: Create LZW-compressed GeoTIFF
     - `tiles`: Generate WebP tiles
     - `both`: Create both outputs

**Fallback Logic Example:**
```
Date: 2015-06-25
- Seattle: Has data for 2015-06-25 → Use 2015-06-25
- Portland: No data, but has 2015-04-10 → Use 2015-04-10
- Dallas: No data yet → Skip (not in vrt_library)
```

This ensures complete coverage for all dates, using the most recent available data for each location.

### 4.4 CLI Usage

newslicer.py is a command-line tool with the following arguments:

**Command-Line Arguments:**

```bash
python newslicer.py [OPTIONS]
```

**Arguments:**

| Argument | Short | Type | Default | Description |
|----------|-------|------|---------|-------------|
| `--source` | `-s` | Path | `/Volumes/drive/newrawtiffs` | Source directory containing TIFF/ZIP files |
| `--output` | `-o` | Path | `/Volumes/drive/sync` | Output directory for COGs/tiles |
| `--csv` | `-c` | Path | `~/archive.aero/master_dole.csv` | Master Dole CSV file with chart metadata |
| `--shapefiles` | `-b` | Path | `~/archive.aero/shapefiles` | Directory containing shapefiles |
| `--format` | `-f` | String | `geotiff` | Output format: `geotiff`, `tiles`, or `both` |
| `--zoom` | `-z` | String | `0-11` | Zoom levels for tile generation (e.g., `0-11`) |

**Usage Examples:**

```bash
# Process all dates with default paths, output GeoTIFF
python newslicer.py

# Custom paths, output both GeoTIFF and tiles
python newslicer.py -s /path/to/charts -o /path/to/output -c master_dole.csv -b shapefiles -f both

# Output only WebP tiles with custom zoom range
python newslicer.py -f tiles -z 0-13

# Process with higher zoom for detailed terminal charts
python newslicer.py -f both -z 0-13
```

**Output Structure:**

```
output_dir/
├── .temp/                       # Temporary processing files
│   └── 2015-06-25/
│       ├── extract/             # Unzipped TIFFs
│       ├── seattle_clipped.tif  # Warped individual charts
│       └── seattle_2015-06-25.vrt # Location-date VRTs
├── 2015-06-25/
│   ├── mosaic_2015-06-25.vrt    # Combined mosaic VRT
│   ├── mosaic_2015-06-25.tif    # GeoTIFF output (if -f geotiff or both)
│   └── tiles/                    # Tile output (if -f tiles or both)
│       ├── 0/0/0.webp
│       └── ...
└── 2015-08-20/
    └── ...
```

### 4.5 GDAL Configuration

newslicer automatically configures GDAL for optimal performance:

```python
# Dynamic cache sizing (uses psutil if available)
available_ram_mb = psutil.virtual_memory().available // (1024 * 1024)
cache_size_mb = max(512, min(4096, available_ram_mb // 2))

# GDAL options
GDAL_CACHEMAX = cache_size_mb          # 512-4096 MB cache
GDAL_NUM_THREADS = 8                   # 8 threads for operations
GDAL_SWATH_SIZE = cache_size_mb        # Swath size for warping
COMPRESS_OVERVIEW = DEFLATE            # Overview compression
GDAL_TIFF_INTERNAL_MASK = YES          # Internal alpha masks
```

### 4.6 Data Validation

#### 4.6.1 Input Validation

**Chart Files:**
- Must be valid GeoTIFF format
- Must have georeferencing information
- Supported formats: `.tif`, `.tiff`, `.zip`

**Shapefiles:**
- Must be valid OGR-readable shapefile
- Must have geometry (polygon/multipolygon)
- Coordinate system can differ (GDAL handles reprojection)

**CSV Metadata:**
- Required columns: `date`, `location`, `edition`
- Optional: `download_link` (for timestamp extraction)
- Encoding: UTF-8 with fallback to 'replace' error handling

#### 4.6.2 Output Validation

**VRT Files:**
- Validated via GDAL dataset open
- Must reference all source files
- Checks for missing input files before processing

**Tile Generation:**
- Exit code check from gdal2tiles.py
- Validates output directory exists and contains tiles
- Logs any errors to GUI

### 4.7 Error Handling

**GDAL Errors:**
```python
gdal.UseExceptions()  # Enable Python exceptions

try:
    ds = gdal.Warp(...)
    if ds:
        ds = None  # Explicit close
        return True
    else:
        self.log("GDAL returned None")
        return False
except Exception as e:
    self.log(f"Error: {e}")
    return False
```

**Thread Exceptions:**
- All processing threads wrapped in try/except
- Exceptions logged with full traceback
- GUI remains responsive
- Processing state reset in `finally` block

**User Notifications:**
- Errors: Logged to ScrolledText widget
- Critical failures: MessageBox dialogs
- Success: Toast notifications + dialog

### 4.8 Configuration Files

The CLI tool does not use external configuration files. All settings are passed as command-line arguments:
- Paths specified via `-s`, `-o`, `-c`, `-b` flags
- Output format via `-f` flag
- Zoom levels via `-z` flag
- No persistent state between runs

**Future Enhancement:**
Consider adding `config.json` or `.ini` for:
- Default paths for different environments
- Zoom level presets per chart type
- Processing parallelization settings
- Compression quality settings

---

## 5. PMTiles Conversion

### 5.1 Overview

After newslicer.py generates GeoTIFF outputs they are converted to PMTiles format for efficient web serving. PMTiles is a single-file archive format for tiled map data that enables serverless map hosting.

### 5.2 Conversion Pipeline

The conversion process has three steps:

1. **Convert GeoTIFF to MBTiles**
2. **Add overviews to MBTiles**
3. **Convert MBTiles to PMTiles**

### 5.3 Step-by-Step Process

#### Step 1: GeoTIFF to MBTiles

```bash
gdal_translate -of MBTILES input_cog.tif out.mbtiles
```

Converts the GeoTIFF/COG to MBTiles format, a SQLite-based tile archive.

**Parameters:**
- `-of MBTILES` - Output format (MBTiles)
- `input_cog.tif` - Source GeoTIFF (can be COG or regular GeoTIFF)
- `out.mbtiles` - Output MBTiles file

**What it does:**
- Reads raster data from GeoTIFF
- Tiles the data into a grid
- Stores tiles in SQLite database
- Preserves projection and georeferencing

#### Step 2: Add Overviews

```bash
gdaladdo -r bilinear out.mbtiles 2 4 8 16 32 64 128 256
```

Adds pyramid overviews to the MBTiles for efficient zooming.

**Parameters:**
- `-r bilinear` - Resampling method (bilinear interpolation)
- `out.mbtiles` - MBTiles file to add overviews to
- `2 4 8 16 32 64 128 256` - Overview levels (powers of 2)

**What it does:**
- Creates downsampled versions of the tiles
- Enables efficient zoom-out rendering
- Uses bilinear resampling for smooth appearance
- Stores overviews in the same MBTiles file

**Alternative Resampling Methods:**
- `nearest` - Nearest neighbor (fast, sharp edges)
- `cubic` - Cubic interpolation (smoother, slower)
- `cubicspline` - Cubic spline (highest quality, slowest)
- `lanczos` - Lanczos windowed sinc (high quality)
- `average` - Average (good for aerial imagery)

#### Step 3: MBTiles to PMTiles

```bash
pmtiles convert out.mbtiles out.pmtiles
```

Converts MBTiles to PMTiles format for serverless hosting.

**Prerequisites:**
- pmtiles CLI tool installed: `go install github.com/protomaps/go-pmtiles/cmd/pmtiles@latest`

**What it does:**
- Reads tiles from SQLite MBTiles
- Reorganizes into cloud-optimized PMTiles format
- Enables HTTP range request serving
- Single-file output (no database)

### 5.4 Complete Example

```bash
#!/bin/bash
# Convert a GeoTIFF mosaic to PMTiles

INPUT="output/2015-06-25/mosaic_2015-06-25.tif"
TEMP_MBTILES="output/2015-06-25/temp.mbtiles"
OUTPUT_PMTILES="output/2015-06-25/2015-06-25.pmtiles"

# Step 1: Convert to MBTiles
echo "Converting GeoTIFF to MBTiles..."
gdal_translate -of MBTILES "$INPUT" "$TEMP_MBTILES"

# Step 2: Add overviews
echo "Adding overviews..."
gdaladdo -r bilinear "$TEMP_MBTILES" 2 4 8 16 32 64 128 256

# Step 3: Convert to PMTiles
echo "Converting to PMTiles..."
pmtiles convert "$TEMP_MBTILES" "$OUTPUT_PMTILES"

# Cleanup temporary MBTiles
rm "$TEMP_MBTILES"

echo "Done! Output: $OUTPUT_PMTILES"
```

### 5.5 PMTiles Benefits

**vs WebP Tiles:**
- **Single file** instead of thousands of individual files
- **HTTP range requests** for efficient partial loading
- **Serverless hosting** on S3/R2 without special configuration
- **Reduced storage overhead** (no file system metadata per tile)
- **Faster uploads** (one file vs thousands)

**vs MBTiles:**
- **Cloud-optimized** structure for HTTP serving
- **No server-side processing** required
- **Byte-range accessible** without SQLite database
- **Smaller file size** in many cases

### 5.6 Serving PMTiles

PMTiles can be served directly from object storage:

**Cloudflare R2:**
```bash
# Upload PMTiles
rclone copy output/2015-06-25/2015-06-25.pmtiles r2:sectionals/pmtiles/

# Serve via public R2 domain
# https://data.archive.aero/pmtiles/2015-06-25.pmtiles
```

**Frontend Integration (Leaflet + PMTiles):**
```javascript
// Using pmtiles JavaScript library
import { PMTiles, leafletRasterLayer } from 'pmtiles';

const p = new PMTiles('https://data.archive.aero/pmtiles/2015-06-25.pmtiles');
leafletRasterLayer(p).addTo(map);
```

### 5.7 Performance Considerations

**Tile Count Estimation:**
- Zoom 0-11: ~5,000-15,000 tiles per date
- Zoom 0-13: ~20,000-60,000 tiles per date

**File Sizes:**
- MBTiles: 8GB MB per date (zoom 0-11)
- PMTiles: 8GB per date (zoom 0-11, ~10-15% smaller)

**Processing Time:**
- GeoTIFF → MBTiles: 40 minutes (depends on size)
- Adding overviews: 20 minutes
- MBTiles → PMTiles: 10 minutes
- **Total: 90 minutes per date**

---

## 6. Data Specifications

### 6.1 Coordinate Reference Systems

**Source Data:**
- Various (typically WGS84 or NAD83)
- Automatically detected by GDAL

**Processing CRS:**
- EPSG:3857 (Web Mercator)
- Required for web tile generation
- Formula: `EPSG:4326 → EPSG:3857`

**Output CRS:**
- Tiles: EPSG:3857
- COG: EPSG:3857 (or original if not tiled)

### 6.2 File Formats

#### 6.2.1 GeoTIFF Specifications

**Input TIFFs:**
- Format: GeoTIFF (any bit depth)
- Compression: Any (LZW, JPEG, uncompressed)
- Bands: RGB, RGBA, or indexed color
- Georeferencing: Embedded or sidecar (.tfw)

**Intermediate TIFFs:**
- Format: GeoTIFF or VRT
- Compression: LZW
- Bands: RGBA (expanded)
- CRS: EPSG:3857
- Tiling: 256x256 internal tiles

**Output GeoTIFF:**
- Format: Cloud Optimized GeoTIFF
- Compression: LZW with PREDICTOR=2
- Bands: RGBA
- CRS: EPSG:3857
- Overviews: Built-in (power-of-2)
- Layout: Tiled with overview sections at beginning

#### 6.2.2 VRT Specifications

**Structure:**
```xml
<VRTDataset rasterXSize="..." rasterYSize="...">
  <SRS>EPSG:3857</SRS>
  <GeoTransform>...</GeoTransform>
  <VRTRasterBand dataType="Byte" band="1">
    <ColorInterp>Red</ColorInterp>
    <ComplexSource>
      <SourceFilename>chart1_warped.tif</SourceFilename>
      ...
    </ComplexSource>
  </VRTRasterBand>
  <!-- Bands 2, 3, 4 (G, B, A) -->
</VRTDataset>
```

**Advantages:**
- Virtual dataset (no data duplication)
- Lightweight (XML file)
- Fast mosaic creation
- Efficient for large areas

**Limitations:**
- Requires source files to remain accessible
- Not portable (absolute/relative paths)
- Can't be directly served (requires rendering)

#### 6.2.3 WebP Tile Format

**Specifications:**
- Format: WebP (lossy)
- Quality: 90 (configurable in gdal2tiles)
- Size: 256x256 pixels
- Transparency: Supported (alpha channel)

**Advantages vs PNG:**
- ~30% smaller file size
- Maintains visual quality
- Browser support: 97%+ (2025)

**File Naming:**
```
{z}/{x}/{y}.webp
```

Where:
- `z` = Zoom level (0-22)
- `x` = Tile column (West to East)
- `y` = Tile row (North to South, XYZ scheme)

### 6.3 Shapefile Specifications

**Required Files:**
- `.shp` - Geometry
- `.shx` - Index
- `.dbf` - Attributes
- `.prj` - Projection (recommended)

**Geometry Requirements:**
- Type: Polygon or MultiPolygon
- Must be valid (no self-intersections)
- CRS: Any (GDAL reprojects automatically)

**Attribute Requirements:**
- None (only geometry used)

**Naming Convention:**
```
shapefiles/
├── seattle.shp
├── seattle.shx
├── seattle.dbf
├── seattle.prj
├── dallas_ft_worth.shp
└── ...
```

Naming should match normalized chart location names.

### 6.4 CSV Metadata Format

**dates.csv (Frontend):**
```csv
date_iso
2011-10-15
2012-09-08
2013-02-15
```

**Fields:**
- `date_iso` - ISO 8601 date (YYYY-MM-DD)

**Sorting:** Dates should be sorted chronologically (enforced in JavaScript)

---

**master_dole.csv (Backend Batch Mode):**
```csv
date,location,edition,download_link
2015-06-25,Seattle,105,https://web.archive.org/web/20150625120000/...
2015-06-25,Portland,104,https://web.archive.org/web/20150625115500/...
```

**Fields:**
- `date` - ISO 8601 date or any parseable format
- `location` - Chart location (normalized in code)
- `edition` - Chart edition number
- `download_link` - Optional Wayback Machine URL

**Encoding:** UTF-8

---

## 7. Tile System Specification

### 7.1 Zoom Level Coverage

**Strategy:** Adaptive zoom based on chart resolution and detail.

**Recommended Ranges:**

| Chart Type | Zoom Range | Rationale |
|------------|------------|-----------|
| Sectional | 0-11 | Continental overview → Local detail |
| Terminal Area | 0-13 | Higher detail for airport vicinities |
| Enroute | 0-9 | Lower detail, large areas |

**Zoom Level Guide:**

| Zoom | Scale | Coverage | Use Case |
|------|-------|----------|----------|
| 0 | 1:591M | World | Initial load |
| 5 | 1:18.5M | Multi-state | Region overview |
| 7 | 1:4.6M | State | Chart selection |
| 9 | 1:1.2M | Metro area | General navigation |
| 11 | 1:288k | City | Detail view |
| 13 | 1:72k | Airport | Terminal charts |

### 7.2 Tile Generation Parameters

**gdal2tiles.py Options:**

```bash
--zoom 0-11              # Zoom range
--processes 14           # Parallel workers
--webviewer=none         # Skip HTML viewer
--exclude                # Skip fully transparent tiles
--tiledriver=WEBP        # Output format
--webp-quality=50        # Quality (0-100, smaller files)
--xyz                    # XYZ tile scheme (CRITICAL!)
```

**Performance Considerations:**

**Process Count:**
```python
cpu_count = max(1, multiprocessing.cpu_count() - 2)
```
- Reserves 2 cores for system responsiveness
- Prevents system lockup during processing

**Tile Exclusion:**
- `--exclude` skips fully transparent tiles
- Reduces storage by ~40% for sectional charts
- Tiles outside chart boundaries not generated

### 7.3 Tile Serving

**CDN Configuration:**

**Origin:** `https://data.archive.aero/sectionals/`

**MIME Types:**
```
.webp → image/webp
```

**CORS Headers:**
```
Access-Control-Allow-Origin: *
Access-Control-Allow-Methods: GET, HEAD
```

**Cache Headers:**
```
Cache-Control: public, max-age=31536000, immutable
```
- Tiles never change (immutable)
- 1-year cache lifetime
- Reduces bandwidth costs

**Compression:**
- WebP is already compressed
- Disable gzip/brotli for `.webp` (wastes CPU)

### 7.4 Tile Caching Strategy

**Browser Cache:**
- Tiles cached indefinitely via Cache-Control
- LocalStorage not needed (Leaflet handles via browser cache)

**Service Worker (Future):**
```javascript
// Potential offline support
self.addEventListener('fetch', (event) => {
  if (event.request.url.includes('/sectionals/')) {
    event.respondWith(
      caches.match(event.request)
        .then(response => response || fetch(event.request))
    );
  }
});
```

### 7.5 Tile Storage Estimates

**Single Date (Zoom 0-11):**
- Average: 2,000-5,000 tiles
- Size: 200-500 MB
- Variance: Depends on chart coverage area

**Full Archive (77 dates):**
- Total tiles: ~250,000
- Total size: ~30 GB
- Per-date average: ~390 MB

**Cost Estimates (Cloudflare R2):**
- Storage: $0.015/GB/month → ~$0.45/month
- Bandwidth: First 10 GB free, then $0.36/GB
- Operations: Minimal (tiles are immutable)

---

## 8. Deployment

### 8.1 Frontend Deployment

**Static Hosting Options:**
1. Cloudflare Pages (recommended)
2. Netlify
3. Vercel
4. GitHub Pages
5. AWS S3 + CloudFront

**Required Files:**
- `index.html`
- `dates.csv`

**Build Process:**
- None required (pure static HTML/CSS/JS)
- Optional: Minification for production

**Environment Variables:**
- None (all config in `CONFIG` object)

**Deployment Steps (Cloudflare Pages):**
```bash
# 1. Install Wrangler CLI
npm install -g wrangler

# 2. Login
wrangler login

# 3. Deploy
wrangler pages deploy . \
  --project-name=archive-aero \
  --branch=main
```

### 8.2 Backend Deployment

**Distribution Methods:**

**1. Source Distribution:**
```bash
# Requirements
python3 -m pip install gdal tkinter

# Run
python3 faa_chart_slicer_gui.py
```

**2. PyInstaller Executable:**
```bash
# Install PyInstaller
pip install pyinstaller

# Create executable
pyinstaller --onefile \
  --windowed \
  --name "FAA Chart Processor" \
  faa_chart_slicer_gui.py

# Output: dist/FAA Chart Processor.app (macOS)
#     or: dist/FAA Chart Processor.exe (Windows)
```

**Challenges:**
- GDAL shared libraries must be bundled
- Complex dependency tree
- Platform-specific builds required

**3. Docker Container:**
```dockerfile
FROM osgeo/gdal:ubuntu-full-3.6.0

RUN apt-get update && apt-get install -y \
    python3-tk \
    python3-pip

COPY newslicer.py /app/
WORKDIR /app

CMD ["python3", "newslicer.py"]
```

Note: CLI tool works in headless Docker containers without X11 forwarding.

### 8.3 Tile Storage Deployment

**Cloudflare R2 Configuration:**

**1. Create Bucket:**
```bash
wrangler r2 bucket create archive-aero-sectionals
```

**2. Configure rclone:**
```ini
[r2]
type = s3
provider = Cloudflare
access_key_id = YOUR_ACCESS_KEY_ID
secret_access_key = YOUR_SECRET_ACCESS_KEY
endpoint = https://YOUR_ACCOUNT_ID.r2.cloudflarestorage.com
acl = private
```

**3. Set Public Access:**
- Create R2 custom domain: `data.archive.aero`
- Configure DNS CNAME
- Enable public read access

**4. Upload Tiles:**
```bash
rclone sync ./output/2015-06-25/ r2:archive-aero-sectionals/sectionals/2015-06-25/
```

### 8.4 Continuous Deployment

**GitHub Actions Workflow:**
```yaml
name: Deploy Frontend

on:
  push:
    branches: [main]

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Deploy to Cloudflare Pages
        uses: cloudflare/wrangler-action@v3
        with:
          apiToken: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          command: pages deploy . --project-name=archive-aero
```

### 8.5 Monitoring & Analytics

**Plausible Analytics:**
- Script: `https://plausible.io/js/pa-m9DzDEgB7Ebb2zKdbBaMF.js`
- Privacy-friendly (no cookies)
- GDPR/CCPA compliant

**Tracked Events:**
- Page views
- Time on site
- Browser/OS distribution
- Geographic distribution

**Custom Events (Potential):**
```javascript
plausible('Timeline Interaction', {
  props: { action: 'play', date: currentDate }
});
```

---

## 9. Performance Considerations

### 9.1 Frontend Performance

**Initial Load Time:**
- Target: < 2 seconds (LCP)
- Optimizations:
  - Inline critical CSS
  - Defer non-critical JS
  - Preconnect to CDN origin

**Runtime Performance:**
- Target: 60 FPS during timeline scrubbing
- Optimizations:
  - 250ms debounce on scrubbing
  - Layer caching (prevents recreation)
  - RequestAnimationFrame for smooth updates

**Memory Management:**
- Leaflet automatically removes off-screen tiles
- `keepBuffer: 2` limits tile retention
- Active layer limit: ~10 layers (167-day window)

**Network Optimization:**
- HTTP/2 multiplexing for parallel tile loads
- Immutable cache headers (infinite cache)
- WebP format (~30% smaller than PNG)

### 9.2 Backend Performance

**Processing Bottlenecks:**

1. **Warping (GDAL):**
   - CPU-intensive
   - Multi-threaded via GDAL options
   - Bilinear resampling (good balance of quality and speed)

2. **Tile Generation (gdal2tiles):**
   - Most time-consuming operation
   - Parallelized across CPU cores
   - I/O-bound at high zoom levels

3. **Compression:**
   - WebP encoding faster than PNG
   - Quality 90 balances size vs speed

**Optimization Strategies:**

**VRT Pipeline:**
- Use VRTs instead of intermediate TIFFs
- Saves disk I/O and processing time
- Trade-off: Source files must remain

**Parallel Processing:**
```python
processes = max(1, cpu_count - 2)
```
- Maximizes CPU utilization
- Reserves cores for system responsiveness

**Memory Management:**
- GDAL streaming (doesn't load entire file to RAM)
- Python garbage collection after each date
- Explicit `ds = None` to close datasets

**Disk I/O:**
- SSD strongly recommended
- Temporary files on separate drive (if available)
- Consider RAM disk for temp files (advanced)

### 9.3 Scalability Considerations

**Frontend:**
- Static files scale infinitely via CDN
- No server-side processing required
- Cost scales linearly with bandwidth

**Backend:**
- Processing time scales linearly with:
  - Number of charts
  - Input file size
  - Zoom level range
  - CPU core count (diminishing returns)

**Storage:**
- Tile storage scales linearly with dates
- Deduplication not applicable (unique per date)
- Cold storage for old tiles (S3 Glacier)

**Bandwidth:**
- Majority of bandwidth from tile serving
- CDN reduces origin load
- Cache hit rate > 90% expected

### 9.4 Performance Monitoring

**Frontend Metrics:**
```javascript
// Measure tile load time
layer.on('load', () => {
  const loadTime = Date.now() - startTime;
  console.log(`Tiles loaded in ${loadTime}ms`);
});
```

**Backend Metrics:**
- Processing time logged per chart
- ETA calculation in ProgressTracker
- Total pipeline time displayed

**Key Performance Indicators:**

| Metric | Target | Measurement |
|--------|--------|-------------|
| Initial page load | < 2s | Lighthouse LCP |
| Timeline step | < 300ms | Custom timing |
| Tile load (cached) | < 50ms | Network panel |
| Tile load (cold) | < 500ms | Network panel |
| Chart processing | < 2 min | Backend log |
| Full date batch | < 30 min | Backend log |

---

## 10. Security Considerations

### 10.1 Frontend Security

**Content Security Policy (CSP):**
```http
Content-Security-Policy:
  default-src 'self';
  script-src 'self' https://unpkg.com https://plausible.io 'unsafe-inline';
  style-src 'self' https://unpkg.com 'unsafe-inline';
  img-src 'self' data: https://*.basemaps.cartocdn.com https://data.archive.aero;
  connect-src 'self' https://data.archive.aero https://nominatim.openstreetmap.org https://ipapi.co;
  font-src 'self';
```

**XSS Prevention:**
- No user-generated content displayed
- URL parameters sanitized (parseFloat, parseInt)
- innerHTML avoided (textContent used)

**CORS Configuration:**
- Tiles served with `Access-Control-Allow-Origin: *`
- Required for cross-origin tile loading

**HTTPS Only:**
- All resources loaded via HTTPS
- Mixed content blocked

### 10.2 Backend Security

**File System Access:**
- CLI restricts file operations to specified directories
- No arbitrary file read/write outside user selections
- Shapefile paths validated before GDAL operations

**Command Injection:**
- GDAL Python bindings used (not shell commands)
- gdal2tiles.py via subprocess with argument list (not shell=True)
- rclone via subprocess with argument list

**Input Validation:**
- File extensions checked before processing
- GDAL validates file formats
- Shapefile geometry validated by OGR

**Temporary Files:**
- Created in user-specified output directory
- Cleaned up on completion (optional)
- No sensitive data in temp files

### 10.3 Data Privacy

**Frontend:**
- No user data collected (Plausible analytics only)
- No cookies or local storage
- IP-based geolocation optional and anonymous

**Backend:**
- No network requests (except optional R2 upload)
- All processing local
- No telemetry or phone-home

### 10.4 API Rate Limiting

**Nominatim (Search):**
- Rate limit: 1 request per second
- Enforced in code: 1000ms cooldown
- User-Agent header: "AeroMap Historical Chart Viewer"

**ipapi.co (Geolocation):**
- Rate limit: 1000 requests/day (free tier)
- Fail gracefully on limit
- Single request per page load

---

## 11. Testing & Quality Assurance

### 11.1 Frontend Testing

**Manual Testing Checklist:**

- [ ] Timeline scrubbing smooth (no lag)
- [ ] Play/pause functionality
- [ ] Forward/backward navigation
- [ ] Keyboard shortcuts work
- [ ] Share URL generates correctly
- [ ] Share URL opens to correct state
- [ ] Mobile responsive layout
- [ ] Touch gestures work (pinch zoom, pan)
- [ ] Location search returns results
- [ ] Auto-geolocation works
- [ ] Split-view synchronization
- [ ] Opacity slider updates tiles
- [ ] All panels open/close correctly
- [ ] Fullscreen toggle works
- [ ] Help overlay displays

**Browser Testing:**
- Chrome 90+ (macOS, Windows, Linux)
- Firefox 88+ (macOS, Windows, Linux)
- Safari 14+ (macOS, iOS)
- Edge 90+ (Windows)

**Performance Testing:**
```javascript
// Measure frame rendering time
const start = performance.now();
timelineApp.update(index);
requestAnimationFrame(() => {
  const duration = performance.now() - start;
  console.log(`Frame update: ${duration}ms`);
});
```

### 11.2 Backend Testing

**Unit Testing (Potential):**
```python
import unittest

class TestChartSlicer(unittest.TestCase):
    def test_warp_and_cut(self):
        slicer = ChartSlicer(
            source_dir=Path("test/source"),
            output_dir=Path("test/output"),
            csv_file=Path("test/test.csv"),
            shape_dir=Path("test/shapefiles")
        )
        result = slicer.warp_and_cut(
            input_tiff=Path("test/input.tif"),
            shapefile=Path("test/boundary.shp"),
            output_tiff=Path("test/output.tif")
        )
        self.assertTrue(result)
        self.assertTrue(Path("test/output.tif").exists())
```

**Integration Testing:**

1. **Manual Mode:**
   - Add sample chart
   - Link shapefile
   - Process with each output format
   - Verify outputs

2. **Batch Mode:**
   - Use test CSV with 2-3 dates
   - Verify file matching
   - Process batch
   - Verify date-specific directories

3. **COG Pipeline:**
   - Create test mosaic
   - Convert to COG
   - Validate with `gdalinfo`

**GDAL Validation:**
```bash
# Validate output TIFF
gdalinfo output.tif

# Check projection
gdalinfo output.tif | grep EPSG

# Validate COG
gdalinfo output_cog.tif | grep -i "overviews"
```

### 11.3 Visual Regression Testing

**Tile Validation:**
1. Generate reference tile set
2. Process same source with updated code
3. Compare tiles visually or via image diff

**Tools:**
- ImageMagick `compare` command
- Python: `PIL.ImageChops.difference()`

### 11.4 Load Testing

**Frontend:**
```javascript
// Simulate rapid timeline scrubbing
for (let i = 0; i < frames.length; i++) {
  setTimeout(() => timelineApp.update(i), i * 100);
}
```

**Backend:**
- Process large batch (20+ dates)
- Monitor CPU/memory usage
- Verify no memory leaks
- Check temp disk usage

---

## 12. Maintenance & Operations

### 12.1 Adding New Dates

**Process:**

1. **Obtain Source Charts:**
   - FAA distribution: https://www.faa.gov/air_traffic/flight_info/aeronav/digital_products/vfr/
   - Wayback Machine archives
   - Manual downloads

2. **Organize Files:**
   ```
   source/
   └── 2025-10-02/
       ├── seattle_sec.tif
       ├── portland_sec.tif
       └── ...
   ```

3. **Update Master CSV:**
   ```csv
   date,location,edition,download_link
   2025-10-02,Seattle,125,https://...
   2025-10-02,Portland,124,https://...
   ```

4. **Process with Batch Mode:**
   - Select source directory
   - Select master CSV
   - Set date filter: `2025-10-02`
   - Review and process

5. **Update Frontend CSV:**
   ```csv
   date_iso
   ...
   2025-10-02
   ```

6. **Upload Tiles:**
   ```bash
   rclone sync output/2025-10-02/ r2:sectionals/2025-10-02/
   ```

7. **Deploy Updated CSV:**
   ```bash
   git add dates.csv
   git commit -m "Add 2025-10-02"
   git push
   ```

### 12.2 Updating Shapefiles

**When Needed:**
- Chart boundaries change
- New charts introduced
- Existing charts split/merged

**Process:**

1. Obtain new shapefile (from FAA or digitize manually)
2. Add to `shapefiles/` directory
3. Test with sample chart
4. Reprocess affected dates if needed

### 12.3 Troubleshooting

**Common Issues:**

**Frontend:**

| Issue | Cause | Solution |
|-------|-------|----------|
| Tiles not loading | CORS error | Check CDN CORS headers |
| Tiles misaligned | TMS vs XYZ | Regenerate with `--xyz` flag |
| Timeline empty | CSV parse error | Validate CSV format |
| Search not working | Rate limit | Wait or reduce requests |

**Backend:**

| Issue | Cause | Solution |
|-------|-------|----------|
| GDAL import error | Missing GDAL | Install GDAL + Python bindings |
| Warp failed | Invalid shapefile | Validate with `ogrinfo` |
| Tile generation slow | Too many processes | Reduce process count |
| Out of memory | File too large | Process smaller regions |
| VRT build failed | Missing source | Check file paths |

**GDAL Debugging:**
```python
import logging
logging.basicConfig(level=logging.DEBUG)

from osgeo import gdal
gdal.SetConfigOption('CPL_DEBUG', 'ON')
```

### 12.4 Backup & Recovery

**Critical Data:**
- Source chart TIFFs (irreplaceable)
- Shapefiles (manually created)
- Master CSV metadata

**Backup Strategy:**
```bash
# Incremental backup
rclone sync source/ backup:archive-aero-source/
rclone sync shapefiles/ backup:archive-aero-shapefiles/
rclone sync master_dole.csv backup:archive-aero-csv/
```

**Recovery:**
- Tiles can be regenerated from sources
- Frontend can be redeployed from Git
- Backend is in version control

---

## 13. Future Enhancements

### 13.1 Frontend Improvements

**Planned:**
- [ ] Service Worker for offline support
- [ ] Date range picker UI
- [ ] Advanced search filters (by chart name)
- [ ] Export current view as image
- [ ] Time-lapse video generation
- [ ] Mobile app (React Native / Flutter)

**Considered:**
- [ ] 3D terrain visualization (Cesium.js)
- [ ] Historical waypoint overlay
- [ ] Flight path animation
- [ ] Change detection highlighting

### 13.2 Backend Improvements

**Planned:**
- [x] CLI interface (implemented: newslicer.py)
- [ ] Configuration file support
- [ ] Incremental processing (skip existing)
- [ ] Parallel date processing
- [ ] Progress persistence (resume after crash)

**Considered:**
- [ ] Cloud processing (AWS Lambda, Google Cloud Run)
- [ ] Distributed processing (multiple machines)
- [ ] GPU acceleration (GDAL CUDA)
- [ ] AI-powered chart enhancement

### 13.3 Data Enhancements

**Planned:**
- [ ] Terminal area charts (TAC)
- [ ] Enroute charts (IFR)
- [ ] Helicopter route charts
- [ ] Grand Canyon chart (special use)

**Considered:**
- [ ] Historical airport data overlay
- [ ] Airspace boundary evolution
- [ ] NOTAM historical archive
- [ ] Weather pattern correlation

---

## 14. Glossary

**COG (Cloud Optimized GeoTIFF):** GeoTIFF variant optimized for cloud storage with HTTP range requests, enabling efficient partial file access.

**EPSG:3857 (Web Mercator):** Spherical Mercator projection used by web mapping systems. Projects Earth onto a square, distorting areas near poles.

**EPSG:4326 (WGS84):** Geographic coordinate system using latitude/longitude. Global standard for GPS and mapping.

**GDAL (Geospatial Data Abstraction Library):** Open-source library for reading, writing, and transforming geospatial raster data.

**OGR:** Vector data handling component of GDAL, supporting shapefiles and other vector formats.

**Sectional Chart:** VFR aeronautical chart covering ~150 nautical miles, updated every 56 days by FAA.

**TMS (Tile Map Service):** Tile scheme with Y-axis origin at bottom-left. Incompatible with most web maps.

**VRT (Virtual Dataset):** XML-based GDAL format describing a virtual raster mosaic without duplicating source data.

**XYZ Tiles:** Tile scheme with Y-axis origin at top-left. Standard for web mapping (Google Maps, Leaflet, OpenStreetMap).

**WebP:** Modern image format developed by Google offering superior compression for web use.

**Cutline:** Vector boundary used to crop raster data, implemented as shapefile polygon.

**Warping:** GDAL operation combining reprojection, resampling, and cropping in a single step.

**Mosaic:** Combined raster dataset from multiple source images, with overlaps resolved.

---

## 15. References

### 15.1 External Documentation

**Leaflet:**
- Official Docs: https://leafletjs.com/reference.html
- Tutorials: https://leafletjs.com/examples.html

**GDAL:**
- GDAL Docs: https://gdal.org/
- Python API: https://gdal.org/api/python.html
- gdal2tiles: https://gdal.org/programs/gdal2tiles.html

**FAA Charts:**
- Aeronautical Charts: https://www.faa.gov/air_traffic/flight_info/aeronav/digital_products/
- Chart Currency: https://www.faa.gov/air_traffic/flight_info/aeronav/digital_products/vfr/

### 15.2 Standards & Specifications

**OGC (Open Geospatial Consortium):**
- GeoTIFF: http://www.opengis.net/def/glossary/term/GeoTIFF
- WMS: https://www.ogc.org/standards/wms

**Tile Specifications:**
- OSGeo Tile Map Service: https://wiki.osgeo.org/wiki/Tile_Map_Service_Specification
- XYZ Tiles: https://developers.google.com/maps/documentation/javascript/coordinates

### 15.3 Related Projects

**Similar Systems:**
- David Rumsey Map Collection: https://www.davidrumsey.com/
- OldMapsOnline: https://www.oldmapsonline.org/
- Wayback Imagery: https://livingatlas.arcgis.com/wayback/

---

## 16. Changelog

### Version 2.5 (2026-01-15)
- **Backend Overhaul:** Replaced GUI application with newslicer.py CLI tool
- Implemented sophisticated 56-location fallback system
- Added PMTiles conversion documentation
- Improved GDAL configuration with dynamic cache sizing
- Updated WebP quality to 50 for smaller files
- Enhanced documentation with complete CLI usage examples

### Version 2.0 (2026-01-13)
- Migrated from tiles.rdnt.io to direct CDN serving
- Implemented XYZ tile scheme (removed TMS)
- Updated tile URL format to direct WebP access
- Simplified CSV format (removed filename column)
- Added progress bar with ETA to backend GUI
- Implemented ProgressTracker class
- Enhanced batch processing progress reporting

### Version 1.5 (2025-12-01)
- Added split-view comparison mode
- Implemented 167-day rolling window
- Enhanced mobile responsiveness
- Added location search and auto-geolocation
- Improved opacity controls

### Version 1.0 (2025-06-01)
- Initial release
- Manual and batch processing modes
- COG generation and R2 upload
- Timeline viewer with 77 dates
- WebP tile generation

---

## 17. License & Attribution

**Code License:** MIT License

**Chart Data:**
- Source: Federal Aviation Administration (FAA)
- Status: Public Domain (U.S. Government Work)
- Usage: Unrestricted

**Attribution Required:**
- Basemap: © OpenStreetMap contributors, © CARTO
- Leaflet: © Leaflet contributors
- GDAL: © OSGeo

---

**Document End**

For questions or contributions, contact: ryan@ryanhemenway.com
