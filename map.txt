SLICER.PY - FAA Chart Processing Tool
================================================================================

PURPOSE:
CLI tool for processing FAA sectional chart sources into date-keyed GeoTIFF
mosaics, then post-processing to MBTiles/PMTiles and uploading PMTiles.

CURRENT TARGET:
- File: slicer.py
- Length: 2420 lines
- Supports single-date and date-range keys from CSV (date/end_date)

ARCHITECTURE:
- Index-first lookup design (source file index + shapefile index)
- Multi-phase pipeline:
  review -> download missing -> warp+clip -> build date mosaic VRT -> GeoTIFF
  -> MBTiles -> PMTiles -> upload
- Parallelism:
  - ThreadPoolExecutor for warp and postprocess/upload tasks
  - ProcessPoolExecutor for GeoTIFF creation

================================================================================
FILE STRUCTURE (CURRENT)
================================================================================

TOP-LEVEL HELPERS
- _get_available_ram_mb()                                 lines 36-44
  - Returns available RAM (psutil if present, fallback if not)

- _auto_postprocess_settings()                            lines 45-87
  - Picks per-worker GDAL threads/cache (Apple Silicon aware)

- _overview_levels_for_mbtiles()                          lines 88-120
  - Computes overview pyramid levels based on MBTiles raster size

- _configure_gdal_for_phase()                             lines 121-144
  - Sets GDAL thread/cache knobs for warp vs GeoTIFF phases

WORKER FUNCTIONS
- create_geotiff_worker(args)                             lines 145-250
  - VRT -> GeoTIFF worker used by ProcessPoolExecutor
  - Handles compression options and ZSTD->LZW fallback on errors

- postprocess_tif_worker(args)                            lines 251-427
  - GeoTIFF -> MBTiles -> PMTiles -> rclone upload
  - Nested helper run(cmd)                                lines 284-427
  - Tracks stage times and supports optional GeoTIFF deletion

MAIN CLASS
- class ChartSlicer                                      starts line 428

CLASS SETUP/UTILS
- _check_zstd_support()                                   lines 432-443
- __init__()                                              lines 444-501
  - Core paths, caches, flags, compression defaults, upload config
- log()                                                   lines 502-512
- normalize_name()                                        lines 513-519
- sanitize_filename()                                     lines 520-531
- _date_from_str()                                        lines 532-542
- _date_range_key()                                       lines 543-550
- _date_key_sort_key()                                    lines 551-556

POSTPROCESS STAGE
- _run_postprocess_upload_stage()                         lines 557-682
  - Bounded queue of TIFF postprocess jobs with heartbeats
- _postprocess_single_tiff()                              lines 683-715

CSV + INDEX BUILD
- load_dole_data()                                        lines 716-752
  - Loads CSV into date_key buckets
  - Supports fallback from tif_filename -> filename
  - Adds wayback_ts parsing from web.archive.org URLs
- _build_source_index()                                   lines 753-784
  - files_by_name and tifs_by_dir caches
- _build_shapefile_index()                                lines 785-811
  - normalized shapefile lookup cache

DOWNLOAD + FILE RESOLUTION
- download_file()                                         lines 812-892
  - throttling + retry + adaptive backoff
- extract_zip()                                           lines 893-930
- _download_missing_files()                               lines 931-1026
- resolve_filename()                                      lines 1027-1113
- find_files()                                            lines 1114-1129
- find_shapefile()                                        lines 1130-1144

GEOSPATIAL PIPELINE
- get_shapefile_srs()                                     lines 1145-1173
- _prepare_warp_job()                                     lines 1174-1212
- _warp_worker()                                          lines 1213-1228
- warp_and_cut()                                          lines 1229-1329
  - Cutline warp to EPSG:3857, optional VRT intermediate output
  - Strict transformer options with relaxed fallback retry
- build_vrt()                                             lines 1330-1370
- create_geotiff()                                        lines 1371-1478

REVIEW + EXECUTION ORCHESTRATION
- _save_review_csv()                                      lines 1479-1530
- generate_review_report()                                lines 1531-1633
  - Builds matrix-style review CSV and prompts y/n
- _rebuild_vrt_library()                                  lines 1634-1717
  - Resume support by scanning temp intermediates
- process_all_dates()                                     lines 1718-2162
  - Main date-loop orchestration

ENTRY POINT
- main()                                                  lines 2163-2420
  - argparse setup, path validation, slicer config wiring
  - review prompt, date-range prompt, then process_all_dates()

================================================================================
CLI ARGUMENTS (CURRENT)
================================================================================

- -s, --source
- -o, --output
- -c, --csv
- -b, --shapefiles
- -t, --temp-dir
- -r, --resample
- --warp-output
- --clip-projwin ULX ULY LRX LRY
- --compression
- --num-threads
- --parallel-geotiff
- --parallel-warp
- --warp-multithread
- --mbtiles-quality
- --upload-jobs
- --postprocess-threads
- --postprocess-cache-mb
- --verbose-external-tools
- --postprocess-only
- --download-delay

================================================================================
PROCESSING FLOW (CURRENT)
================================================================================

1. Startup and validation
   - parse args, verify source/csv/shapefile paths, create output/temp dirs

2. Initialize slicer state
   - set compression/resample/parallel/upload options from CLI

3. Optional postprocess-only path
   - skip warp/GeoTIFF creation
   - run TIFF -> MBTiles -> PMTiles -> upload against existing output TIFFs

4. Pre-processing review path (default full run)
   - load_dole_data()
   - build source + shapefile indexes
   - set preview_mode=True
   - generate_review_report() and require y/n confirmation

5. Date scope selection
   - prompt for all dates or explicit YYYY-MM-DD range
   - set preview_mode=False

6. process_all_dates()
   - compute locations and sorted date keys
   - download missing files up front (throttled)
   - rebuild temp VRT library for resume support
   - per date:
     - skip if output GeoTIFF already exists
     - group records by (location, edition)
     - run parallel warp jobs with duplicate-row fallback attempts
     - build date mosaic VRT
     - queue GeoTIFF job
   - run queued GeoTIFF jobs in process pool
   - retry failed GeoTIFF jobs sequentially

7. Postprocess/upload stage
   - for each valid output GeoTIFF:
     - gdal_translate -> MBTiles (WEBP tiles)
     - gdaladdo overviews
     - pmtiles convert
     - rclone copyto remote
     - optional delete input GeoTIFF

================================================================================
KEY STATE STRUCTURES
================================================================================

- self.dole_data:
  Dict[date_key, List[csv_row]]
  where date_key is "YYYY-MM-DD" or "YYYY-MM-DD_to_YYYY-MM-DD"

- self.date_key_map:
  Dict[date_key, (start_date, end_date)]

- self.files_by_name:
  Dict[file_name, Path] for O(1) source lookup

- self.tifs_by_dir:
  Dict[zip_stem_dir, List[Path]] for extracted ZIP contents

- self.shapefile_index:
  Dict[normalized_location, Path] for O(1) shapefile lookup

- vrt_library (runtime):
  Dict[normalized_location, Dict[date_key, List[Path]]]
  used to build per-date mosaics and support resume behavior

================================================================================
